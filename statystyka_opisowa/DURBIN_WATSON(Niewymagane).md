
<span style="color:red">**[NIEWYMAGANE]**</span>

# Test Durbina-Watsona (Durbin-Watson Test)

## Kim byli Durbin i Watson?

**James Durbin** (1923-2012) by≈Ç brytyjskim statystykiem, profesorem na London School of Economics, znanym z prac nad szeregami czasowymi i ekonometriƒÖ. **Geoffrey Watson** (1921-1998) by≈Ç australijskim statystykiem, kt√≥ry r√≥wnie≈º wni√≥s≈Ç znaczƒÖcy wk≈Çad w teoriƒô statystyki matematycznej. W 1950 roku wsp√≥lnie opracowali test s≈Çu≈ºƒÖcy do wykrywania autokorelacji w resztach modeli regresji.

## Czym jest test Durbina-Watsona?

Test Durbina-Watsona (DW test) to **test statystyczny s≈Çu≈ºƒÖcy do wykrywania autokorelacji pierwszego rzƒôdu w resztach modelu regresji liniowej**. Test sprawdza, czy kolejne reszty (b≈Çƒôdy) w modelu sƒÖ ze sobƒÖ skorelowane, co narusza jedno z podstawowych za≈Ço≈ºe≈Ñ klasycznej regresji liniowej.

### Po co testowaƒá autokorelacjƒô reszt?

W klasycznej regresji liniowej zak≈Çadamy, ≈ºe reszty sƒÖ:
- niezale≈ºne od siebie
- losowe
- nie wykazujƒÖ ≈ºadnego wzorca

Je≈õli reszty sƒÖ skorelowane (autokorelacja), oznacza to ≈ºe:
- **Model jest ≈∫le specyfikowany** - np. brakuje wa≈ºnej zmiennej
- **Standardowe b≈Çƒôdy sƒÖ niedoszacowane** - testy istotno≈õci sƒÖ niewiarygodne
- **Prognozy sƒÖ nieefektywne** - mo≈ºna je poprawiƒá
- **Mo≈ºe istnieƒá trend lub sezonowo≈õƒá** - nieuwzglƒôdnione w modelu

## Wz√≥r matematyczny:

### Statystyka Durbina-Watsona:
$$
DW = \frac{\sum_{t=2}^{n} (e_t - e_{t-1})^2}{\sum_{t=1}^{n} e_t^2}
$$

Gdzie:
- $e_t$ = reszta (b≈ÇƒÖd) w okresie $t$
- $n$ = liczba obserwacji
- Licznik = suma kwadrat√≥w r√≥≈ºnic kolejnych reszt
- Mianownik = suma kwadrat√≥w reszt

### Alternatywna postaƒá (przybli≈ºona):
$$
DW \approx 2(1 - \rho)
$$

Gdzie:
- $\rho$ = wsp√≥≈Çczynnik autokorelacji pierwszego rzƒôdu reszt
- $\rho = \frac{\text{Cov}(e_t, e_{t-1})}{\text{Var}(e_t)}$

## Interpretacja warto≈õci DW:

### Zakres warto≈õci:
Statystyka DW przyjmuje warto≈õci od **0 do 4**:

```
0                    2                    4
|--------------------|--------------------|
Silna dodatnia       Brak                Silna ujemna
autokorelacja        autokorelacji       autokorelacja
```

### Szczeg√≥≈Çowa interpretacja:

| Warto≈õƒá DW | Interpretacja | Znaczenie |
|------------|---------------|-----------|
| **DW = 2** | Brak autokorelacji | Idealna sytuacja, reszty niezale≈ºne |
| **DW < 2** | Dodatnia autokorelacja | Kolejne reszty podobne do siebie |
| **DW > 2** | Ujemna autokorelacja | Kolejne reszty naprzemienne (zig-zag) |
| **DW ‚âà 0** | Bardzo silna dodatnia | Reszty "podƒÖ≈ºajƒÖ" za sobƒÖ |
| **DW ‚âà 4** | Bardzo silna ujemna | Reszty zmieniajƒÖ znak co okres |

### Praktyczne granice (rule of thumb):

**Brak autokorelacji (OK):**
- **1.5 < DW < 2.5** - zwykle akceptowalne
- **1.8 < DW < 2.2** - bardzo dobre

**Problem autokorelacji:**
- **DW < 1.5** - dodatnia autokorelacja (problem!)
- **DW > 2.5** - ujemna autokorelacja (problem!)

## Formalne regu≈Çy decyzyjne:

Test Durbina-Watsona u≈ºywa warto≈õci krytycznych z tablic:

### Warto≈õci krytyczne: $d_L$ (dolna) i $d_U$ (g√≥rna)

Zale≈ºƒÖ od:
- Liczby obserwacji ($n$)
- Liczby zmiennych obja≈õniajƒÖcych ($k$)
- Poziomu istotno≈õci (zwykle $\alpha = 0.05$)

### Regu≈Çy decyzyjne:

```
0        d_L       d_U        2      4-d_U    4-d_L      4
|--------|---------|----------|--------|--------|--------|
  Dodatnia  ?    Brak auto-    ?     Ujemna
  autokore-      korelacji          autokore-
  lacja                             lacja

  H‚ÇÅ        ?         H‚ÇÄ         ?        H‚ÇÅ
```

**Interpretacja:**
1. **DW < $d_L$**: Odrzucamy H‚ÇÄ - jest **dodatnia autokorelacja**
2. **$d_L$ ‚â§ DW ‚â§ $d_U$**: **Nieokre≈õlone** - test niekonkluzywny
3. **$d_U$ < DW < 4-$d_U$**: Nie odrzucamy H‚ÇÄ - **brak autokorelacji**
4. **4-$d_U$ ‚â§ DW ‚â§ 4-$d_L$**: **Nieokre≈õlone** - test niekonkluzywny
5. **DW > 4-$d_L$**: Odrzucamy H‚ÇÄ - jest **ujemna autokorelacja**

### Hipotezy:
- **H‚ÇÄ**: Brak autokorelacji pierwszego rzƒôdu ($\rho = 0$)
- **H‚ÇÅ**: Jest autokorelacja pierwszego rzƒôdu ($\rho \neq 0$)

## Przyk≈Çad praktyczny w Python:

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from statsmodels.stats.stattools import durbin_watson
import seaborn as sns

# Ustawienia
np.random.seed(42)
plt.style.use('seaborn-v0_8-darkgrid')

print("=" * 70)
print("TEST DURBINA-WATSONA - PRZYK≈ÅADY")
print("=" * 70)

# ============================================================================
# PRZYK≈ÅAD 1: Reszty BEZ autokorelacji (prawid≈Çowy model)
# ============================================================================

print("\n### PRZYK≈ÅAD 1: Model BEZ autokorelacji ###\n")

# Generowanie danych
n = 100
X = np.linspace(0, 10, n).reshape(-1, 1)
# Prawdziwa zale≈ºno≈õƒá: y = 2 + 3*x + szum losowy (niezale≈ºny)
y_true = 2 + 3 * X.flatten()
noise = np.random.normal(0, 1, n)  # Szum niezale≈ºny
y = y_true + noise

# Regresja
model = LinearRegression()
model.fit(X, y)
y_pred = model.predict(X)
residuals = y - y_pred

# Test Durbina-Watsona
dw_stat = durbin_watson(residuals)

print(f"Wsp√≥≈Çczynniki modelu: a = {model.intercept_:.4f}, b = {model.coef_[0]:.4f}")
print(f"\nStatystyka Durbina-Watsona: {dw_stat:.4f}")

# Interpretacja
if 1.5 < dw_stat < 2.5:
    print("‚úì WNIOSEK: BRAK autokorelacji (DW ‚âà 2)")
    print("  Model jest poprawnie specyfikowany")
elif dw_stat <= 1.5:
    print("‚úó PROBLEM: Dodatnia autokorelacja (DW < 1.5)")
else:
    print("‚úó PROBLEM: Ujemna autokorelacja (DW > 2.5)")

# Wizualizacja
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. Dopasowanie modelu
axes[0, 0].scatter(X, y, alpha=0.6, label='Dane')
axes[0, 0].plot(X, y_pred, 'r-', linewidth=2, label='Dopasowanie')
axes[0, 0].set_xlabel('X')
axes[0, 0].set_ylabel('Y')
axes[0, 0].set_title('Model: Y = a + b*X')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# 2. Reszty w czasie
axes[0, 1].plot(residuals, marker='o', linestyle='-', alpha=0.6)
axes[0, 1].axhline(y=0, color='r', linestyle='--')
axes[0, 1].set_xlabel('Obserwacja')
axes[0, 1].set_ylabel('Reszta')
axes[0, 1].set_title(f'Reszty w czasie (DW = {dw_stat:.4f})')
axes[0, 1].grid(True, alpha=0.3)

# 3. Reszty vs reszty op√≥≈∫nione (lag plot)
axes[1, 0].scatter(residuals[:-1], residuals[1:], alpha=0.6)
axes[1, 0].axhline(y=0, color='r', linestyle='--', alpha=0.3)
axes[1, 0].axvline(x=0, color='r', linestyle='--', alpha=0.3)
axes[1, 0].set_xlabel('Reszta(t)')
axes[1, 0].set_ylabel('Reszta(t+1)')
axes[1, 0].set_title('Lag Plot - Autokorelacja reszt')
axes[1, 0].grid(True, alpha=0.3)

# 4. ACF (Autocorrelation Function)
from statsmodels.graphics.tsaplots import plot_acf
plot_acf(residuals, lags=20, ax=axes[1, 1], alpha=0.05)
axes[1, 1].set_title('Funkcja Autokorelacji (ACF)')

plt.tight_layout()
plt.savefig('durbin_watson_example1.png', dpi=100, bbox_inches='tight')
plt.show()

# ============================================================================
# PRZYK≈ÅAD 2: Reszty Z dodatniƒÖ autokorelacjƒÖ (problem!)
# ============================================================================

print("\n\n### PRZYK≈ÅAD 2: Model Z dodatniƒÖ autokorelacjƒÖ ###\n")

# Generowanie danych z autokorelacjƒÖ
X2 = np.linspace(0, 10, n).reshape(-1, 1)
y2_true = 2 + 3 * X2.flatten()

# Szum z autokorelacjƒÖ AR(1): e_t = 0.7*e_{t-1} + ŒΩ_t
noise_ar = np.zeros(n)
noise_ar[0] = np.random.normal(0, 1)
for t in range(1, n):
    noise_ar[t] = 0.7 * noise_ar[t-1] + np.random.normal(0, 1)

y2 = y2_true + noise_ar

# Regresja
model2 = LinearRegression()
model2.fit(X2, y2)
y2_pred = model2.predict(X2)
residuals2 = y2 - y2_pred

# Test Durbina-Watsona
dw_stat2 = durbin_watson(residuals2)

print(f"Wsp√≥≈Çczynniki modelu: a = {model2.intercept_:.4f}, b = {model2.coef_[0]:.4f}")
print(f"\nStatystyka Durbina-Watsona: {dw_stat2:.4f}")

# Interpretacja
if 1.5 < dw_stat2 < 2.5:
    print("‚úì WNIOSEK: BRAK autokorelacji (DW ‚âà 2)")
elif dw_stat2 <= 1.5:
    print("‚úó PROBLEM: Dodatnia autokorelacja (DW < 1.5)")
    print("  Reszty sƒÖ skorelowane - model wymaga poprawy!")
    print("  Mo≈ºliwe rozwiƒÖzania:")
    print("  ‚Ä¢ Dodaj op√≥≈∫nionƒÖ zmiennƒÖ zale≈ºnƒÖ")
    print("  ‚Ä¢ Dodaj brakujƒÖce zmienne obja≈õniajƒÖce")
    print("  ‚Ä¢ U≈ºyj metod szereg√≥w czasowych (ARIMA, VAR)")
else:
    print("‚úó PROBLEM: Ujemna autokorelacja (DW > 2.5)")

# Wizualizacja
fig2, axes2 = plt.subplots(2, 2, figsize=(14, 10))

# 1. Dopasowanie modelu
axes2[0, 0].scatter(X2, y2, alpha=0.6, label='Dane')
axes2[0, 0].plot(X2, y2_pred, 'r-', linewidth=2, label='Dopasowanie')
axes2[0, 0].set_xlabel('X')
axes2[0, 0].set_ylabel('Y')
axes2[0, 0].set_title('Model z autokorelowanymi resztami')
axes2[0, 0].legend()
axes2[0, 0].grid(True, alpha=0.3)

# 2. Reszty w czasie
axes2[0, 1].plot(residuals2, marker='o', linestyle='-', alpha=0.6, color='red')
axes2[0, 1].axhline(y=0, color='black', linestyle='--')
axes2[0, 1].set_xlabel('Obserwacja')
axes2[0, 1].set_ylabel('Reszta')
axes2[0, 1].set_title(f'Reszty w czasie (DW = {dw_stat2:.4f}) - PROBLEM!')
axes2[0, 1].grid(True, alpha=0.3)

# 3. Lag plot - wyra≈∫na dodatnia korelacja
axes2[1, 0].scatter(residuals2[:-1], residuals2[1:], alpha=0.6, color='red')
axes2[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.3)
axes2[1, 0].axvline(x=0, color='black', linestyle='--', alpha=0.3)
# Dodaj liniƒô trendu
z = np.polyfit(residuals2[:-1], residuals2[1:], 1)
p = np.poly1d(z)
x_line = np.linspace(residuals2[:-1].min(), residuals2[:-1].max(), 100)
axes2[1, 0].plot(x_line, p(x_line), "b--", linewidth=2, label='Trend')
axes2[1, 0].set_xlabel('Reszta(t)')
axes2[1, 0].set_ylabel('Reszta(t+1)')
axes2[1, 0].set_title('Lag Plot - Widoczna dodatnia autokorelacja!')
axes2[1, 0].legend()
axes2[1, 0].grid(True, alpha=0.3)

# 4. ACF
plot_acf(residuals2, lags=20, ax=axes2[1, 1], alpha=0.05)
axes2[1, 1].set_title('ACF - Istotne op√≥≈∫nienia!')

plt.tight_layout()
plt.savefig('durbin_watson_example2.png', dpi=100, bbox_inches='tight')
plt.show()

# ============================================================================
# PRZYK≈ÅAD 3: Por√≥wnanie r√≥≈ºnych poziom√≥w autokorelacji
# ============================================================================

print("\n\n### PRZYK≈ÅAD 3: Por√≥wnanie r√≥≈ºnych poziom√≥w autokorelacji ###\n")

# R√≥≈ºne wsp√≥≈Çczynniki autokorelacji
rho_values = [0.0, 0.3, 0.5, 0.7, 0.9]
dw_results = []

fig3, axes3 = plt.subplots(2, 3, figsize=(16, 10))
axes3 = axes3.flatten()

for idx, rho in enumerate(rho_values):
    # Generowanie danych z r√≥≈ºnym œÅ
    X_temp = np.linspace(0, 10, n).reshape(-1, 1)
    y_temp_true = 2 + 3 * X_temp.flatten()

    # Szum z autokorelacjƒÖ
    noise_temp = np.zeros(n)
    noise_temp[0] = np.random.normal(0, 1)
    for t in range(1, n):
        noise_temp[t] = rho * noise_temp[t-1] + np.random.normal(0, 1)

    y_temp = y_temp_true + noise_temp

    # Regresja
    model_temp = LinearRegression()
    model_temp.fit(X_temp, y_temp)
    y_temp_pred = model_temp.predict(X_temp)
    residuals_temp = y_temp - y_temp_pred

    # DW
    dw_temp = durbin_watson(residuals_temp)
    dw_results.append({'rho': rho, 'DW': dw_temp})

    # Teoretyczna warto≈õƒá: DW ‚âà 2(1-œÅ)
    dw_theory = 2 * (1 - rho)

    # Wykres reszt
    axes3[idx].plot(residuals_temp, marker='o', linestyle='-', alpha=0.6)
    axes3[idx].axhline(y=0, color='r', linestyle='--')
    axes3[idx].set_title(f'œÅ = {rho:.1f}: DW = {dw_temp:.3f}\n(teoria: {dw_theory:.3f})')
    axes3[idx].set_xlabel('Obserwacja')
    axes3[idx].set_ylabel('Reszta')
    axes3[idx].grid(True, alpha=0.3)

# Usu≈Ñ ostatni pusty subplot
fig3.delaxes(axes3[5])

plt.tight_layout()
plt.savefig('durbin_watson_comparison.png', dpi=100, bbox_inches='tight')
plt.show()

# Podsumowanie wynik√≥w
print("\nPodsumowanie r√≥≈ºnych poziom√≥w autokorelacji:")
print("-" * 60)
print(f"{'œÅ (autok.)':<15} {'DW stat':<15} {'DW teoria':<15} {'Wniosek'}")
print("-" * 60)

for result in dw_results:
    rho = result['rho']
    dw = result['DW']
    dw_theory = 2 * (1 - rho)

    if 1.5 < dw < 2.5:
        conclusion = "OK"
    elif dw <= 1.5:
        conclusion = "Problem (dodatnia)"
    else:
        conclusion = "Problem (ujemna)"

    print(f"{rho:<15.1f} {dw:<15.3f} {dw_theory:<15.3f} {conclusion}")

print("\nüí° WNIOSEK: Im wy≈ºsza autokorelacja (œÅ), tym ni≈ºsza statystyka DW")
```

## Funkcja pomocnicza do analizy DW:

```python
def analyze_durbin_watson(residuals, n_vars=1, alpha=0.05, verbose=True):
    """
    Kompleksowa analiza testu Durbina-Watsona

    Parameters:
    -----------
    residuals : array-like
        Reszty z modelu regresji
    n_vars : int
        Liczba zmiennych obja≈õniajƒÖcych (bez wyrazu wolnego)
    alpha : float
        Poziom istotno≈õci
    verbose : bool
        Czy wy≈õwietlaƒá szczeg√≥≈Çowe informacje

    Returns:
    --------
    dict : S≈Çownik z wynikami testu
    """
    from statsmodels.stats.stattools import durbin_watson

    # Obliczanie statystyki DW
    dw_stat = durbin_watson(residuals)

    # Przybli≈ºony wsp√≥≈Çczynnik autokorelacji
    rho_approx = 1 - dw_stat / 2

    # Interpretacja
    if 1.5 < dw_stat < 2.5:
        interpretation = "Brak autokorelacji"
        status = "OK"
    elif dw_stat <= 1.5:
        interpretation = "Dodatnia autokorelacja"
        status = "PROBLEM"
    else:
        interpretation = "Ujemna autokorelacja"
        status = "PROBLEM"

    results = {
        'DW_statistic': dw_stat,
        'rho_approx': rho_approx,
        'interpretation': interpretation,
        'status': status,
        'n_obs': len(residuals),
        'n_vars': n_vars
    }

    if verbose:
        print("=" * 60)
        print("ANALIZA DURBINA-WATSONA")
        print("=" * 60)
        print(f"\nStatystyka DW: {dw_stat:.4f}")
        print(f"Przybli≈ºone œÅ: {rho_approx:.4f}")
        print(f"\nInterpretacja: {interpretation}")
        print(f"Status: {status}")

        if status == "PROBLEM":
            print("\n‚ö† OSTRZE≈ªENIE: Wykryto autokorelacjƒô!")
            print("\nMo≈ºliwe rozwiƒÖzania:")
            print("  1. Dodaj op√≥≈∫nionƒÖ zmiennƒÖ zale≈ºnƒÖ: Y_{t-1}")
            print("  2. Dodaj brakujƒÖce zmienne obja≈õniajƒÖce")
            print("  3. Sprawd≈∫ trend lub sezonowo≈õƒá")
            print("  4. U≈ºyj modeli szereg√≥w czasowych (ARIMA, VAR)")
            print("  5. Zastosuj estymacjƒô z korektƒÖ (Newey-West, HAC)")
        else:
            print("\n‚úì Model spe≈Çnia za≈Ço≈ºenie o braku autokorelacji")

        print("\nGranice interpretacyjne:")
        print("  ‚Ä¢ DW ‚âà 2.0: Brak autokorelacji")
        print("  ‚Ä¢ 1.5 < DW < 2.5: Zwykle akceptowalne")
        print("  ‚Ä¢ DW < 1.5: Dodatnia autokorelacja (problem)")
        print("  ‚Ä¢ DW > 2.5: Ujemna autokorelacja (problem)")

    return results

# Przyk≈Çad u≈ºycia
# results = analyze_durbin_watson(residuals, n_vars=2)
```

## Ograniczenia testu Durbina-Watsona:

### 1. **Wykrywa tylko autokorelacjƒô pierwszego rzƒôdu:**
```python
# Test DW nie wykryje autokorelacji wy≈ºszych rzƒôd√≥w
# Dla AR(2): e_t = œÅ‚ÇÅ*e_{t-1} + œÅ‚ÇÇ*e_{t-2} + ŒΩ_t
# U≈ºyj zamiast tego testu Breuscha-Godfreya
```

### 2. **Wymaga sta≈Çej macierzy X:**
- Nie dzia≈Ça gdy X zawiera op√≥≈∫nionƒÖ zmiennƒÖ zale≈ºnƒÖ
- Nie dzia≈Ça w modelach autoregresyjnych

### 3. **Strefy nieokre≈õlone:**
- Miƒôdzy $d_L$ i $d_U$ test nie daje jednoznacznej odpowiedzi

### 4. **Zak≈Çada normalno≈õƒá reszt:**
- W przypadku silnych odchyle≈Ñ od normalno≈õci mo≈ºe dawaƒá b≈Çƒôdne wyniki

## Alternatywne testy autokorelacji:

### Test Breuscha-Godfreya (bardziej og√≥lny):
```python
from statsmodels.stats.diagnostic import acorr_breusch_godfrey

# Test autokorelacji do p-tego rzƒôdu
bg_test = acorr_breusch_godfrey(model, nlags=4)

print("Test Breuscha-Godfreya:")
print(f"LM statistic: {bg_test[0]:.4f}")
print(f"p-value: {bg_test[1]:.4f}")

if bg_test[1] < 0.05:
    print("‚úó Odrzucamy H‚ÇÄ: Jest autokorelacja")
else:
    print("‚úì Nie odrzucamy H‚ÇÄ: Brak autokorelacji")
```

### Test Ljunga-Boxa (dla szereg√≥w czasowych):
```python
from statsmodels.stats.diagnostic import acorr_ljungbox

# Test dla reszt
lb_test = acorr_ljungbox(residuals, lags=10, return_df=True)

print("\nTest Ljunga-Boxa:")
print(lb_test)
```

## Praktyczne zastosowania:

### 1. **Ekonometria:**
- Weryfikacja modeli regresji ekonomicznych
- Analiza danych panelowych
- Modele makroekonomiczne

### 2. **Szeregi czasowe:**
- Diagnostyka modeli ARIMA
- Weryfikacja za≈Ço≈ºe≈Ñ VAR
- Analiza prognoz

### 3. **Finanse:**
- Modele wyceny aktyw√≥w
- Analiza zwrot√≥w
- Testy efektywno≈õci rynku

### 4. **Kontrola jako≈õci:**
- Analiza proces√≥w produkcyjnych
- Monitorowanie stabilno≈õci
- Detekcja trend√≥w

## Przyk≈Çad z rzeczywistymi danymi:

```python
# Przyk≈Çad z danymi makroekonomicznymi
import pandas as pd
from sklearn.linear_model import LinearRegression
from statsmodels.stats.stattools import durbin_watson

# Za≈Ç√≥≈ºmy, ≈ºe mamy dane PKB i konsumpcji
# df = pd.read_csv('dane_makro.csv')

# Prosty model: Konsumpcja = f(PKB)
# X = df[['PKB']].values
# y = df['Konsumpcja'].values

# model = LinearRegression()
# model.fit(X, y)
# y_pred = model.predict(X)
# residuals = y - y_pred

# dw_stat = durbin_watson(residuals)

# Interpretacja w kontek≈õcie ekonomicznym
# if dw_stat < 1.5:
#     print("Dodatnia autokorelacja mo≈ºe wskazywaƒá na:")
#     print("  ‚Ä¢ Brak zmiennej reprezentujƒÖcej trendy czasowe")
#     print("  ‚Ä¢ Cykliczno≈õƒá gospodarcza nie ujƒôta w modelu")
#     print("  ‚Ä¢ Op√≥≈∫nione reakcje konsument√≥w na zmiany PKB")
```

## Podsumowanie:

| W≈Ça≈õciwo≈õƒá | Opis |
|------------|------|
| **Cel** | Wykrywanie autokorelacji pierwszego rzƒôdu w resztach |
| **Zakres** | 0 do 4 (idea≈Ç: ‚âà 2) |
| **H‚ÇÄ** | Brak autokorelacji ($\rho = 0$) |
| **Interpretacja** | DW < 1.5: problem, 1.5-2.5: OK, DW > 2.5: problem |
| **Zastosowanie** | Diagnostyka modeli regresji liniowej |
| **Ograniczenia** | Tylko AR(1), nie dzia≈Ça z op√≥≈∫nionƒÖ zmiennƒÖ zale≈ºnƒÖ |
| **Alternatywy** | Test Breuscha-Godfreya, test Ljunga-Boxa |

**Test Durbina-Watsona** jest fundamentalnym narzƒôdziem diagnostycznym w ekonometrii, pozwalajƒÖcym szybko zweryfikowaƒá jedno z kluczowych za≈Ço≈ºe≈Ñ klasycznej regresji liniowej - niezale≈ºno≈õƒá reszt. Mimo ogranicze≈Ñ, pozostaje najpopularniejszym testem autokorelacji ze wzglƒôdu na prostotƒô interpretacji i powszechnƒÖ dostƒôpno≈õƒá w oprogramowaniu statystycznym.
